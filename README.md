# üìä Relat√≥rio Completo de An√°lise e Transforma√ß√£o de Dados

### üéØ Objetivo:
O objetivo deste projeto foi aplicar conceitos de estat√≠stica descritiva, medidas de dispers√£o, an√°lise de correla√ß√£o, integra√ß√£o de dados, corre√ß√£o de valores inconsistentes, remo√ß√£o de redund√¢ncias e transforma√ß√£o de dados em uma base de clientes. Este relat√≥rio documenta detalhadamente todas as etapas realizadas, os m√©todos utilizados e os resultados obtidos.

### üë§ Integrantes:
-Juliana Alves
-Leonardo Mucci
-Marcos Vinicius
-Rodrigo Veloso

---

## Parte 1: Estat√≠stica Descritiva

### 1.1 Carregamento e Limpeza dos Dados

#### üìö Bibliotecas Utilizadas:
- pandas: Para manipula√ß√£o e an√°lise de dados.
- scipy: Para c√°lculo da moda.

#### üîß Fun√ß√µes e M√©todos:
- `pd.read_csv()`: Carrega a base de dados de um arquivo CSV.
- `DataFrame.drop_duplicates()`: Remove registros duplicados.
- `DataFrame.replace()`: Substitui valores inconsistentes.
- `DataFrame.quantile()`: Calcula os quartis dos dados.

#### üíª C√≥digo:
```python
import pandas as pd
from scipy import stats

# Carregar a base de clientes
df_clientes = pd.read_csv('https://iafatec.s3.amazonaws.com/atividade/clientes.csv')

# Limpeza de Dados
df_clientes = df_clientes[(df_clientes['idade'] >= 18) & (df_clientes['idade'] <= 70)]
df_clientes = df_clientes[(df_clientes['altura_cm'] >= 150) & (df_clientes['altura_cm'] <= 200)]
df_clientes['sexo'] = df_clientes['sexo'].replace(['Desconhecido', 'Outro'], 'N√£o Informado')
df_clientes = df_clientes[(df_clientes['salario'] >= 0) & (df_clientes['salario'] <= 100000)]
df_clientes['score_bom_pagador'] = df_clientes['score_bom_pagador'].replace({'A': 10, 'B': 8, 'C': 6, 'D': 4, 'E': 2})
df_clientes = df_clientes.drop_duplicates()
```

#### üìÑ Descri√ß√£o:
- **Carregamento dos Dados**: Utilizamos a fun√ß√£o `pd.read_csv()` para carregar a base de clientes de um arquivo CSV.
- **Limpeza dos Dados**: Removemos registros com idades, alturas, sexos e sal√°rios inconsistentes, al√©m de registros duplicados.

### 1.2 C√°lculo das Estat√≠sticas Descritivas

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.mean()`: Calcula a m√©dia dos dados.
- `DataFrame.median()`: Calcula a mediana dos dados.
- `stats.mode()`: Calcula a moda dos dados.
- `DataFrame.quantile()`: Calcula os quartis dos dados.

#### üíª C√≥digo:
```python

# Calcular a m√©dia, mediana, moda e intervalo interquartil para atributos num√©ricos
media = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].mean()
mediana = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].median()
moda_idade = stats.mode(df_clientes['idade'].dropna(), keepdims=True)
moda_altura = stats.mode(df_clientes['altura_cm'].dropna(), keepdims=True)
moda_salario = stats.mode(df_clientes['salario'].dropna(), keepdims=True)
moda_peso = stats.mode(df_clientes['peso'].dropna(), keepdims=True)

moda = {
    'idade': moda_idade.mode[0] if moda_idade.count[0] > 0 else 'Nenhuma moda',
    'altura_cm': moda_altura.mode[0] if moda_altura.count[0] > 0 else 'Nenhuma moda',
    'salario': moda_salario.mode[0] if moda_salario.count[0] > 0 else 'Nenhuma moda',
    'peso': moda_peso.mode[0] if moda_peso.count[0] > 0 else 'Nenhuma moda'
}

# Calcular o intervalo interquartil para atributos num√©ricos
intervalo_interquartil = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].quantile([0.25, 0.75])
intervalo_interquartil.index = ['Q1', 'Q3']

# Organizar os resultados em um DataFrame
resultados = pd.DataFrame({
    'M√©dia': media,
    'Mediana': mediana,
    'Moda': list(moda.values()),
    'Q1': intervalo_interquartil.loc['Q1'],
    'Q3': intervalo_interquartil.loc['Q3']
})

# Adicionar a coluna do IQR
resultados['IQR'] = resultados.loc['Q3'] - resultados.loc['Q1']

# Exibir os resultados em forma de tabela
print("\nResumo Estat√≠stico dos Atributos Num√©ricos:\n")
print(resultados.to_string())


```

#### üìÑ Descri√ß√£o:
- **C√°lculo da M√©dia, Mediana, Moda e Intervalo Interquartil**: Utilizamos m√©todos do Pandas e SciPy para calcular as estat√≠sticas descritivas dos atributos num√©ricos.

### 1.3 Distribui√ß√£o de Frequ√™ncia dos Atributos Categ√≥ricos

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.value_counts()`: Conta a frequ√™ncia dos valores categ√≥ricos.
- `Series.rename_axis()`: Renomeia o eixo de uma Series.
- `Series.reset_index()`: Reseta o √≠ndice da Series.

#### üíª C√≥digo:
```python

# Descrever a distribui√ß√£o de frequ√™ncia dos atributos categ√≥ricos
frequencia_sexo = df_clientes['sexo'].value_counts().rename_axis('Sexo').reset_index(name='Frequ√™ncia')
frequencia_genero_musical = df_clientes['genero_musical_favorito'].value_counts().rename_axis('G√™nero Musical Favorito').reset_index(name='Frequ√™ncia')
frequencia_cidade = df_clientes['cidade'].value_counts().rename_axis('Cidade').reset_index(name='Frequ√™ncia')
frequencia_profissao = df_clientes['profissao'].value_counts().rename_axis('Profiss√£o').reset_index(name='Frequ√™ncia')

# Exibir as frequ√™ncias em forma de tabela
print("\nDistribui√ß√£o de Frequ√™ncia dos Atributos Categ√≥ricos:\n")
print("Sexo:\n", frequencia_sexo.to_string(index=False))
print("\nG√™nero Musical Favorito:\n", frequencia_genero_musical.to_string(index=False))
print("\nCidade:\n", frequencia_cidade.to_string(index=False))
print("\nProfiss√£o:\n", frequencia_profissao.to_string(index=False))


```

#### üìÑ Descri√ß√£o:
- **Distribui√ß√£o de Frequ√™ncia**: Utilizamos `value_counts()` para contar a frequ√™ncia dos valores categ√≥ricos e formatamos a sa√≠da com `rename_axis()` e `reset_index()`.

---

## Parte 2: Medidas de Dispers√£o, Vari√¢ncia e Desvio-Padr√£o

### 2.1 Carregamento e Limpeza dos Dados
Os dados foram carregados e limpos conforme descrito na Parte 1.

### 2.2 C√°lculo das Medidas de Dispers√£o

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.max()`: Calcula o valor m√°ximo dos dados.
- `DataFrame.min()`: Calcula o valor m√≠nimo dos dados.
- `DataFrame.var()`: Calcula a vari√¢ncia dos dados.
- `DataFrame.std()`: Calcula o desvio-padr√£o dos dados.

#### üíª C√≥digo:
```python

# Calcular a amplitude, vari√¢ncia e desvio-padr√£o para atributos num√©ricos
amplitude = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].max() - df_clientes[['idade', 'altura_cm', 'salario', 'peso']].min()
variancia = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].var()
desvio_padrao = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].std()

# Organizar os resultados em um DataFrame
resultados_dispersao = pd.DataFrame({
    'Amplitude': amplitude,
    'Vari√¢ncia': variancia,
    'Desvio-Padr√£o': desvio_padrao
})

# Exibir os resultados em forma de tabela
print("\nMedidas de Dispers√£o dos Atributos Num√©ricos:\n")
print(resultados_dispersao.to_string())


```

#### üìÑ Descri√ß√£o:
- **C√°lculo da Amplitude, Vari√¢ncia e Desvio-Padr√£o**: Utilizamos m√©todos do Pandas para calcular as medidas de dispers√£o dos atributos num√©ricos.

---

## Parte 3: An√°lise de Correla√ß√£o e Representa√ß√µes Gr√°ficas

### 3.1 Carregamento e Limpeza dos Dados
Os dados foram carregados e limpos conforme descrito na Parte 1.

### 3.2 An√°lise de Correla√ß√£o

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.corr()`: Calcula a matriz de correla√ß√£o dos dados.

#### üíª C√≥digo:
```python

# An√°lise de Correla√ß√£o
correlacao = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].corr()

# Identificar pares de atributos com correla√ß√£o forte
correlacao_forte = correlacao[(correlacao > 0.7) | (correlacao < -0.7)]
print("\nMatriz de Correla√ß√£o:\n")
print(correlacao.to_string())

print("\nPares de Atributos com Correla√ß√£o Forte (|corr| > 0.7):\n")
print(correlacao_forte.to_string())

```

#### üìÑ Descri√ß√£o:
- **An√°lise de Correla√ß√£o**: Utilizamos o m√©todo `corr()` do Pandas para calcular a matriz de correla√ß√£o entre os atributos num√©ricos.

### 3.3 Representa√ß√µes Gr√°ficas

#### üìö Bibliotecas Utilizadas:
- matplotlib: Para gera√ß√£o de gr√°ficos.
- seaborn: Para visualiza√ß√£o de dados estat√≠sticos.

#### üîß Fun√ß√µes e M√©todos:
- `sns.histplot()`: Gera histogramas.
- `sns.boxplot()`: Gera box plots.
- `sns.scatterplot()`: Gera gr√°ficos de dispers√£o.
- `sns.heatmap()`: Gera mapas de calor.

#### üíª C√≥digo:
```python

import matplotlib.pyplot as plt
import seaborn as sns

# Histogramas para atributos num√©ricos
for coluna in ['idade', 'altura_cm', 'salario', 'peso']:
    plt.figure()
    sns.histplot(df_clientes[coluna], kde=True)
    plt.title(f'Histograma de {coluna}')
    plt.xlabel(coluna)
    plt.ylabel('Frequ√™ncia')
    plt.savefig(f'histograma_{coluna}.png')

# Box plots para atributos num√©ricos (individuais)
for coluna in ['idade', 'altura_cm', 'salario', 'peso']:
    plt.figure()
    sns.boxplot(y=df_clientes[coluna])
    plt.title(f'Box Plot de {coluna}')
    plt.ylabel(coluna)
    plt.savefig(f'boxplot_{coluna}.png')

# Gr√°ficos de dispers√£o para pares de atributos com correla√ß√£o forte
for coluna1 in ['idade', 'altura_cm', 'salario', 'peso']:
    for coluna2 in ['idade', 'altura_cm', 'salario', 'peso']:
        if coluna1 != coluna2 and abs(correlacao.loc[coluna1, coluna2]) > 0.7:
            plt.figure()
            sns.scatterplot(x=df_clientes[coluna1], y=df_clientes[coluna2])
            plt.title(f'Dispers√£o entre {coluna1} e {coluna2}')
            plt.xlabel(coluna1)
            plt.ylabel(coluna2)
            plt.savefig(f'dispersao_{coluna1}_{coluna2}.png')

# Mapa de calor para a matriz de correla√ß√£o
plt.figure(figsize=(10, 8))
sns.heatmap(correlacao, annot=True, cmap='coolwarm', center=0)
plt.title('Mapa de Calor da Matriz de Correla√ß√£o')
plt.savefig('mapa_calor_correlacao.png')

plt.show()


```

#### üìÑ Descri√ß√£o:
- **Histogramas, Box Plots, Gr√°ficos de Dispers√£o e Mapas de Calor**: Utilizamos seaborn e matplotlib para criar diversas visualiza√ß√µes gr√°ficas, que ajudam na interpreta√ß√£o dos dados.

---

## Parte 4: Integra√ß√£o de Dados, Valores Inconsistentes e Redund√¢ncia de Dados

### 4.1 Integra√ß√£o de Dados

#### üìÑ Descri√ß√£o:
Assumimos que os dados j√° est√£o integrados. Em um cen√°rio real, descrever√≠amos a necessidade de integrar dados de m√∫ltiplas fontes, como combinar dados de diferentes sistemas ou departamentos.

### 4.2 Identifica√ß√£o e Corre√ß√£o de Valores Inconsistentes

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.replace()`: Substitui valores inconsistentes.
- `DataFrame.drop_duplicates()`: Remove registros duplicados.

#### üíª C√≥digo:
```python

# Identificar e corrigir valores inconsistentes nos atributos:
# - Idade negativa ou fora do intervalo plaus√≠vel (18-70 anos)
# - Altura fora do intervalo normal (150-200 cm)
# - Sexo inconsistente
# - Sal√°rio fora do intervalo razo√°vel (0-100000)
# - Score Bom Pagador inconsistente

# Corrigir idades inconsistentes
df_clientes = df_clientes[(df_clientes['idade'] >= 18) & (df_clientes['idade'] <= 70)]

# Corrigir alturas inconsistentes
df_clientes = df_clientes[(df_clientes['altura_cm'] >= 150) & (df_clientes['altura_cm'] <= 200)]

# Uniformizar valores inconsistentes em 'sexo'
df_clientes['sexo'] = df_clientes['sexo'].replace(['Desconhecido', 'Outro'], 'N√£o Informado')

# Corrigir sal√°rios inconsistentes
df_clientes = df_clientes[(df_clientes['salario'] >= 0) & (df_clientes['salario'] <= 100000)]

# Corrigir valores inconsistentes em 'score_bom_pagador'
df_clientes['score_bom_pagador'] = df_clientes['score_bom_pagador'].replace({'A': 10, 'B': 8, 'C': 6, 'D': 4, 'E': 2})


```

#### üìÑ Descri√ß√£o:
- **Corre√ß√£o de Valores Inconsistentes**: Removemos registros com valores inconsistentes em atributos como idade, altura, sexo, sal√°rio e score bom pagador.

### 4.3 Identifica√ß√£o e Remo√ß√£o de Redund√¢ncias

#### üîß Fun√ß√µes e M√©todos:
- `DataFrame.drop_duplicates()`: Remove registros duplicados.
- `DataFrame.drop()`: Remove colunas redundantes.

#### üíª C√≥digo:
```python

# Identificar e remover dados redundantes (duplicatas e colunas redundantes)
# Remover duplicatas
df_clientes = df_clientes.drop_duplicates()

# Remover colunas redundantes (exemplo: suponha que a coluna 'idade' seja redundante)
# df_clientes = df_clientes.drop(columns=['idade'])

# Exibir o DataFrame Processado
print("\nDataFrame Processado:\n")
print(df_clientes.head())

print("\nResumo do DataFrame Processado:\n")
print(df_clientes.info())

print("\nEstat√≠sticas Descritivas do DataFrame Processado:\n")
print(df_clientes.describe())


```

#### üìÑ Descri√ß√£o:
- **Remo√ß√£o de Redund√¢ncias**: Removemos registros duplicados e colunas redundantes, garantindo a consist√™ncia dos dados.

---

## Parte 5: Transforma√ß√£o de Dados

### 5.1 Normaliza√ß√£o de Dados

#### üìö Bibliotecas Utilizadas:
- sklearn.preprocessing: Para normaliza√ß√£o e codifica√ß√£o dos dados.

#### üîß Fun√ß√µes e M√©todos:
- `MinMaxScaler()`: Aplica a normaliza√ß√£o Min-Max nos dados.

#### üíª C√≥digo:
```python

from sklearn.preprocessing import MinMaxScaler

# Selecionar colunas num√©ricas para normaliza√ß√£o
colunas_numericas = ['idade', 'altura_cm', 'score_bom_pagador', 'salario', 'peso']

# Instanciar o MinMaxScaler
scaler = MinMaxScaler()

# Aplicar a normaliza√ß√£o Min-Max
df_clientes[colunas_numericas] = scaler.fit_transform(df_clientes[colunas_numericas])


```

#### üìÑ Descri√ß√£o:
- **Normaliza√ß√£o de Dados**: Utilizamos `MinMaxScaler` para normalizar os atributos num√©ricos no intervalo [0, 1].

### 5.2 Codifica√ß√£o de Dados Categ√≥ricos

#### üîß Fun√ß√µes e M√©todos:
- `OneHotEncoder()`: Aplica a codifica√ß√£o One-Hot nos dados categ√≥ricos.

#### üíª C√≥digo:
```python

from sklearn.preprocessing import OneHotEncoder

# Instanciar o OneHotEncoder
encoder = OneHotEncoder(sparse_output=False)

# Codificar o atributo 'sexo'
sexo_encoded = encoder.fit_transform(df_clientes[['sexo']])
sexo_encoded_df = pd.DataFrame(sexo_encoded, columns=encoder.get_feature_names_out(['sexo']))

# Codificar o atributo 'genero_musical_favorito'
genero_encoded = encoder.fit_transform(df_clientes[['genero_musical_favorito']])
genero_encoded_df = pd.DataFrame(genero_encoded, columns=encoder.get_feature_names_out(['genero_musical_favorito']))

# Concatenar as colunas codificadas ao DataFrame original
df_clientes = pd.concat([df_clientes, sexo_encoded_df, genero_encoded_df], axis=1)

# Remover colunas originais categ√≥ricas
df_clientes = df_clientes.drop(columns=['sexo', 'genero_musical_favorito'])

# Exibir o DataFrame Processado
print("\nDataFrame Processado:\n")
print(df_clientes.head())

print("\nResumo do DataFrame Processado:\n")
print(df_clientes.info())

print("\nEstat√≠sticas Descritivas do DataFrame Processado:\n")
print(df_clientes.describe())


```

#### üìÑ Descri√ß√£o:
- **Codifica√ß√£o de Dados Categ√≥ricos**: Utilizamos `OneHotEncoder` para transformar atributos categ√≥ricos em vari√°veis dummy, permitindo seu uso em modelos de aprendizado de m√°quina.

---

## üí•Conclus√£o

Neste projeto, aplicamos uma abordagem abrangente para a an√°lise e transforma√ß√£o de uma base de dados de clientes, utilizando uma variedade de t√©cnicas estat√≠sticas e computacionais. As etapas seguidas inclu√≠ram a limpeza e prepara√ß√£o dos dados, o c√°lculo de estat√≠sticas descritivas, a an√°lise de correla√ß√£o, a visualiza√ß√£o gr√°fica dos dados, a corre√ß√£o de valores inconsistentes, a remo√ß√£o de redund√¢ncias e a transforma√ß√£o de dados para fins de modelagem.

Os principais resultados obtidos incluem:

- **Limpeza e Prepara√ß√£o de Dados**: Conseguimos identificar e corrigir valores inconsistentes e duplicados, garantindo a qualidade dos dados para an√°lises subsequentes.
- **Estat√≠sticas Descritivas**: Foram calculadas medidas centrais (m√©dia, mediana, moda) e medidas de dispers√£o (vari√¢ncia, desvio-padr√£o, amplitude), fornecendo uma vis√£o clara das caracter√≠sticas dos dados.
- **An√°lise de Correla√ß√£o**: Identificamos rela√ß√µes significativas entre diferentes atributos num√©ricos, o que pode guiar futuras an√°lises e decis√µes baseadas em dados.
- **Visualiza√ß√µes Gr√°ficas**: Criamos diversas representa√ß√µes visuais, como histogramas, box plots, gr√°ficos de dispers√£o e mapas de calor, que ajudaram a interpretar os dados de maneira intuitiva e informativa.
- **Transforma√ß√£o de Dados**: Normalizamos os dados num√©ricos e codificamos os atributos categ√≥ricos, tornando os dados prontos para uso em modelos de aprendizado de m√°quina e outras an√°lises avan√ßadas.

Este projeto demonstrou a import√¢ncia de um processo bem-estruturado de an√°lise e transforma√ß√£o de dados para extrair insights valiosos e garantir a qualidade dos dados. As t√©cnicas aplicadas aqui s√£o fundamentais para qualquer an√°lise de dados robusta e servem como base para futuras an√°lises mais complexas e modelagens preditivas.



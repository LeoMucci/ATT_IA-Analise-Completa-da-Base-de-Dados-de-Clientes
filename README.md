# ðŸ“Š RelatÃ³rio Completo de AnÃ¡lise e TransformaÃ§Ã£o de Dados

### ðŸŽ¯ Objetivo:
O objetivo deste projeto foi aplicar conceitos de estatÃ­stica descritiva, medidas de dispersÃ£o, anÃ¡lise de correlaÃ§Ã£o, integraÃ§Ã£o de dados, correÃ§Ã£o de valores inconsistentes, remoÃ§Ã£o de redundÃ¢ncias e transformaÃ§Ã£o de dados em uma base de clientes. Este relatÃ³rio documenta detalhadamente todas as etapas realizadas, os mÃ©todos utilizados e os resultados obtidos.

### ðŸ‘¤ Integrantes:
-Juliana Alves
-Leonardo Mucci
-Marcos Vinicius
-Rodrigo Veloso

---

## Parte 1: EstatÃ­stica Descritiva

### 1.1 Carregamento e Limpeza dos Dados

#### ðŸ“š Bibliotecas Utilizadas:
- pandas: Para manipulaÃ§Ã£o e anÃ¡lise de dados.
- scipy: Para cÃ¡lculo da moda.

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `pd.read_csv()`: Carrega a base de dados de um arquivo CSV.
- `DataFrame.drop_duplicates()`: Remove registros duplicados.
- `DataFrame.replace()`: Substitui valores inconsistentes.
- `DataFrame.quantile()`: Calcula os quartis dos dados.

#### ðŸ’» CÃ³digo:
```python
import pandas as pd
from scipy import stats

# Carregar a base de clientes
df_clientes = pd.read_csv('https://iafatec.s3.amazonaws.com/atividade/clientes.csv')

# Limpeza de Dados
df_clientes = df_clientes[(df_clientes['idade'] >= 18) & (df_clientes['idade'] <= 70)]
df_clientes = df_clientes[(df_clientes['altura_cm'] >= 150) & (df_clientes['altura_cm'] <= 200)]
df_clientes['sexo'] = df_clientes['sexo'].replace(['Desconhecido', 'Outro'], 'NÃ£o Informado')
df_clientes = df_clientes[(df_clientes['salario'] >= 0) & (df_clientes['salario'] <= 100000)]
df_clientes['score_bom_pagador'] = df_clientes['score_bom_pagador'].replace({'A': 10, 'B': 8, 'C': 6, 'D': 4, 'E': 2})
df_clientes = df_clientes.drop_duplicates()
```

#### ðŸ“„ DescriÃ§Ã£o:
- **Carregamento dos Dados**: Utilizamos a funÃ§Ã£o `pd.read_csv()` para carregar a base de clientes de um arquivo CSV.
- **Limpeza dos Dados**: Removemos registros com idades, alturas, sexos e salÃ¡rios inconsistentes, alÃ©m de registros duplicados.

### 1.2 CÃ¡lculo das EstatÃ­sticas Descritivas

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.mean()`: Calcula a mÃ©dia dos dados.
- `DataFrame.median()`: Calcula a mediana dos dados.
- `stats.mode()`: Calcula a moda dos dados.
- `DataFrame.quantile()`: Calcula os quartis dos dados.

#### ðŸ’» CÃ³digo:
```python

# Calcular a mÃ©dia, mediana, moda e intervalo interquartil para atributos numÃ©ricos
media = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].mean()
mediana = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].median()
moda_idade = stats.mode(df_clientes['idade'].dropna(), keepdims=True)
moda_altura = stats.mode(df_clientes['altura_cm'].dropna(), keepdims=True)
moda_salario = stats.mode(df_clientes['salario'].dropna(), keepdims=True)
moda_peso = stats.mode(df_clientes['peso'].dropna(), keepdims=True)

moda = {
    'idade': moda_idade.mode[0] if moda_idade.count[0] > 0 else 'Nenhuma moda',
    'altura_cm': moda_altura.mode[0] if moda_altura.count[0] > 0 else 'Nenhuma moda',
    'salario': moda_salario.mode[0] if moda_salario.count[0] > 0 else 'Nenhuma moda',
    'peso': moda_peso.mode[0] if moda_peso.count[0] > 0 else 'Nenhuma moda'
}

# Calcular o intervalo interquartil para atributos numÃ©ricos
intervalo_interquartil = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].quantile([0.25, 0.75])
intervalo_interquartil.index = ['Q1', 'Q3']

# Organizar os resultados em um DataFrame
resultados = pd.DataFrame({
    'MÃ©dia': media,
    'Mediana': mediana,
    'Moda': list(moda.values()),
    'Q1': intervalo_interquartil.loc['Q1'],
    'Q3': intervalo_interquartil.loc['Q3']
})

# Adicionar a coluna do IQR
resultados['IQR'] = resultados.loc['Q3'] - resultados.loc['Q1']

# Exibir os resultados em forma de tabela
print("\nResumo EstatÃ­stico dos Atributos NumÃ©ricos:\n")
print(resultados.to_string())


```

#### ðŸ“„ DescriÃ§Ã£o:
- **CÃ¡lculo da MÃ©dia, Mediana, Moda e Intervalo Interquartil**: Utilizamos mÃ©todos do Pandas e SciPy para calcular as estatÃ­sticas descritivas dos atributos numÃ©ricos.

### 1.3 DistribuiÃ§Ã£o de FrequÃªncia dos Atributos CategÃ³ricos

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.value_counts()`: Conta a frequÃªncia dos valores categÃ³ricos.
- `Series.rename_axis()`: Renomeia o eixo de uma Series.
- `Series.reset_index()`: Reseta o Ã­ndice da Series.

#### ðŸ’» CÃ³digo:
```python

# Descrever a distribuiÃ§Ã£o de frequÃªncia dos atributos categÃ³ricos
frequencia_sexo = df_clientes['sexo'].value_counts().rename_axis('Sexo').reset_index(name='FrequÃªncia')
frequencia_genero_musical = df_clientes['genero_musical_favorito'].value_counts().rename_axis('GÃªnero Musical Favorito').reset_index(name='FrequÃªncia')
frequencia_cidade = df_clientes['cidade'].value_counts().rename_axis('Cidade').reset_index(name='FrequÃªncia')
frequencia_profissao = df_clientes['profissao'].value_counts().rename_axis('ProfissÃ£o').reset_index(name='FrequÃªncia')

# Exibir as frequÃªncias em forma de tabela
print("\nDistribuiÃ§Ã£o de FrequÃªncia dos Atributos CategÃ³ricos:\n")
print("Sexo:\n", frequencia_sexo.to_string(index=False))
print("\nGÃªnero Musical Favorito:\n", frequencia_genero_musical.to_string(index=False))
print("\nCidade:\n", frequencia_cidade.to_string(index=False))
print("\nProfissÃ£o:\n", frequencia_profissao.to_string(index=False))


```

#### ðŸ“„ DescriÃ§Ã£o:
- **DistribuiÃ§Ã£o de FrequÃªncia**: Utilizamos `value_counts()` para contar a frequÃªncia dos valores categÃ³ricos e formatamos a saÃ­da com `rename_axis()` e `reset_index()`.

---

## Parte 2: Medidas de DispersÃ£o, VariÃ¢ncia e Desvio-PadrÃ£o

### 2.1 Carregamento e Limpeza dos Dados
Os dados foram carregados e limpos conforme descrito na Parte 1.

### 2.2 CÃ¡lculo das Medidas de DispersÃ£o

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.max()`: Calcula o valor mÃ¡ximo dos dados.
- `DataFrame.min()`: Calcula o valor mÃ­nimo dos dados.
- `DataFrame.var()`: Calcula a variÃ¢ncia dos dados.
- `DataFrame.std()`: Calcula o desvio-padrÃ£o dos dados.

#### ðŸ’» CÃ³digo:
```python

# Calcular a amplitude, variÃ¢ncia e desvio-padrÃ£o para atributos numÃ©ricos
amplitude = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].max() - df_clientes[['idade', 'altura_cm', 'salario', 'peso']].min()
variancia = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].var()
desvio_padrao = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].std()

# Organizar os resultados em um DataFrame
resultados_dispersao = pd.DataFrame({
    'Amplitude': amplitude,
    'VariÃ¢ncia': variancia,
    'Desvio-PadrÃ£o': desvio_padrao
})

# Exibir os resultados em forma de tabela
print("\nMedidas de DispersÃ£o dos Atributos NumÃ©ricos:\n")
print(resultados_dispersao.to_string())


```

#### ðŸ“„ DescriÃ§Ã£o:
- **CÃ¡lculo da Amplitude, VariÃ¢ncia e Desvio-PadrÃ£o**: Utilizamos mÃ©todos do Pandas para calcular as medidas de dispersÃ£o dos atributos numÃ©ricos.

---

## Parte 3: AnÃ¡lise de CorrelaÃ§Ã£o e RepresentaÃ§Ãµes GrÃ¡ficas

### 3.1 Carregamento e Limpeza dos Dados
Os dados foram carregados e limpos conforme descrito na Parte 1.

### 3.2 AnÃ¡lise de CorrelaÃ§Ã£o

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.corr()`: Calcula a matriz de correlaÃ§Ã£o dos dados.

#### ðŸ’» CÃ³digo:
```python

# AnÃ¡lise de CorrelaÃ§Ã£o
correlacao = df_clientes[['idade', 'altura_cm', 'salario', 'peso']].corr()

# Identificar pares de atributos com correlaÃ§Ã£o forte
correlacao_forte = correlacao[(correlacao > 0.7) | (correlacao < -0.7)]
print("\nMatriz de CorrelaÃ§Ã£o:\n")
print(correlacao.to_string())

print("\nPares de Atributos com CorrelaÃ§Ã£o Forte (|corr| > 0.7):\n")
print(correlacao_forte.to_string())

```

#### ðŸ“„ DescriÃ§Ã£o:
- **AnÃ¡lise de CorrelaÃ§Ã£o**: Utilizamos o mÃ©todo `corr()` do Pandas para calcular a matriz de correlaÃ§Ã£o entre os atributos numÃ©ricos.

### 3.3 RepresentaÃ§Ãµes GrÃ¡ficas

#### ðŸ“š Bibliotecas Utilizadas:
- matplotlib: Para geraÃ§Ã£o de grÃ¡ficos.
- seaborn: Para visualizaÃ§Ã£o de dados estatÃ­sticos.

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `sns.histplot()`: Gera histogramas.
- `sns.boxplot()`: Gera box plots.
- `sns.scatterplot()`: Gera grÃ¡ficos de dispersÃ£o.
- `sns.heatmap()`: Gera mapas de calor.

#### ðŸ’» CÃ³digo:
```python

import matplotlib.pyplot as plt
import seaborn as sns

# Histogramas para atributos numÃ©ricos
for coluna in ['idade', 'altura_cm', 'salario', 'peso']:
    plt.figure()
    sns.histplot(df_clientes[coluna], kde=True)
    plt.title(f'Histograma de {coluna}')
    plt.xlabel(coluna)
    plt.ylabel('FrequÃªncia')
    plt.savefig(f'histograma_{coluna}.png')

# Box plots para atributos numÃ©ricos (individuais)
for coluna in ['idade', 'altura_cm', 'salario', 'peso']:
    plt.figure()
    sns.boxplot(y=df_clientes[coluna])
    plt.title(f'Box Plot de {coluna}')
    plt.ylabel(coluna)
    plt.savefig(f'boxplot_{coluna}.png')

# GrÃ¡ficos de dispersÃ£o para pares de atributos com correlaÃ§Ã£o forte
for coluna1 in ['idade', 'altura_cm', 'salario', 'peso']:
    for coluna2 in ['idade', 'altura_cm', 'salario', 'peso']:
        if coluna1 != coluna2 and abs(correlacao.loc[coluna1, coluna2]) > 0.7:
            plt.figure()
            sns.scatterplot(x=df_clientes[coluna1], y=df_clientes[coluna2])
            plt.title(f'DispersÃ£o entre {coluna1} e {coluna2}')
            plt.xlabel(coluna1)
            plt.ylabel(coluna2)
            plt.savefig(f'dispersao_{coluna1}_{coluna2}.png')

# Mapa de calor para a matriz de correlaÃ§Ã£o
plt.figure(figsize=(10, 8))
sns.heatmap(correlacao, annot=True, cmap='coolwarm', center=0)
plt.title('Mapa de Calor da Matriz de CorrelaÃ§Ã£o')
plt.savefig('mapa_calor_correlacao.png')

plt.show()


```

#### ðŸ“„ DescriÃ§Ã£o:
- **Histogramas, Box Plots, GrÃ¡ficos de DispersÃ£o e Mapas de Calor**: Utilizamos seaborn e matplotlib para criar diversas visualizaÃ§Ãµes grÃ¡ficas, que ajudam na interpretaÃ§Ã£o dos dados.

---

## Parte 4: IntegraÃ§Ã£o de Dados, Valores Inconsistentes e RedundÃ¢ncia de Dados

### 4.1 IntegraÃ§Ã£o de Dados

#### ðŸ“„ DescriÃ§Ã£o:
Assumimos que os dados jÃ¡ estÃ£o integrados. Em um cenÃ¡rio real, descreverÃ­amos a necessidade de integrar dados de mÃºltiplas fontes, como combinar dados de diferentes sistemas ou departamentos.

### 4.2 IdentificaÃ§Ã£o e CorreÃ§Ã£o de Valores Inconsistentes

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.replace()`: Substitui valores inconsistentes.
- `DataFrame.drop_duplicates()`: Remove registros duplicados.

#### ðŸ’» CÃ³digo:
```python

# Identificar e corrigir valores inconsistentes nos atributos:
# - Idade negativa ou fora do intervalo plausÃ­vel (18-70 anos)
# - Altura fora do intervalo normal (150-200 cm)
# - Sexo inconsistente
# - SalÃ¡rio fora do intervalo razoÃ¡vel (0-100000)
# - Score Bom Pagador inconsistente

# Corrigir idades inconsistentes
df_clientes = df_clientes[(df_clientes['idade'] >= 18) & (df_clientes['idade'] <= 70)]

# Corrigir alturas inconsistentes
df_clientes = df_clientes[(df_clientes['altura_cm'] >= 150) & (df_clientes['altura_cm'] <= 200)]

# Uniformizar valores inconsistentes em 'sexo'
df_clientes['sexo'] = df_clientes['sexo'].replace(['Desconhecido', 'Outro'], 'NÃ£o Informado')

# Corrigir salÃ¡rios inconsistentes
df_clientes = df_clientes[(df_clientes['salario'] >= 0) & (df_clientes['salario'] <= 100000)]

# Corrigir valores inconsistentes em 'score_bom_pagador'
df_clientes['score_bom_pagador'] = df_clientes['score_bom_pagador'].replace({'A': 10, 'B': 8, 'C': 6, 'D': 4, 'E': 2})


```

#### ðŸ“„ DescriÃ§Ã£o:
- **CorreÃ§Ã£o de Valores Inconsistentes**: Removemos registros com valores inconsistentes em atributos como idade, altura, sexo, salÃ¡rio e score bom pagador.

### 4.3 IdentificaÃ§Ã£o e RemoÃ§Ã£o de RedundÃ¢ncias

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `DataFrame.drop_duplicates()`: Remove registros duplicados.
- `DataFrame.drop()`: Remove colunas redundantes.

#### ðŸ’» CÃ³digo:
```python

# Identificar e remover dados redundantes (duplicatas e colunas redundantes)
# Remover duplicatas
df_clientes = df_clientes.drop_duplicates()

# Remover colunas redundantes (exemplo: suponha que a coluna 'idade' seja redundante)
# df_clientes = df_clientes.drop(columns=['idade'])

# Exibir o DataFrame Processado
print("\nDataFrame Processado:\n")
print(df_clientes.head())

print("\nResumo do DataFrame Processado:\n")
print(df_clientes.info())

print("\nEstatÃ­sticas Descritivas do DataFrame Processado:\n")
print(df_clientes.describe())


```

#### ðŸ“„ DescriÃ§Ã£o:
- **RemoÃ§Ã£o de RedundÃ¢ncias**: Removemos registros duplicados e colunas redundantes, garantindo a consistÃªncia dos dados.

---

## Parte 5: TransformaÃ§Ã£o de Dados

### 5.1 NormalizaÃ§Ã£o de Dados

#### ðŸ“š Bibliotecas Utilizadas:
- sklearn.preprocessing: Para normalizaÃ§Ã£o e codificaÃ§Ã£o dos dados.

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `MinMaxScaler()`: Aplica a normalizaÃ§Ã£o Min-Max nos dados.

#### ðŸ’» CÃ³digo:
```python

from sklearn.preprocessing import MinMaxScaler

# Selecionar colunas numÃ©ricas para normalizaÃ§Ã£o
colunas_numericas = ['idade', 'altura_cm', 'score_bom_pagador', 'salario', 'peso']

# Instanciar o MinMaxScaler
scaler = MinMaxScaler()

# Aplicar a normalizaÃ§Ã£o Min-Max
df_clientes[colunas_numericas] = scaler.fit_transform(df_clientes[colunas_numericas])


```

#### ðŸ“„ DescriÃ§Ã£o:
- **NormalizaÃ§Ã£o de Dados**: Utilizamos `MinMaxScaler` para normalizar os atributos numÃ©ricos no intervalo [0, 1].

### 5.2 CodificaÃ§Ã£o de Dados CategÃ³ricos

#### ðŸ”§ FunÃ§Ãµes e MÃ©todos:
- `OneHotEncoder()`: Aplica a codificaÃ§Ã£o One-Hot nos dados categÃ³ricos.

#### ðŸ’» CÃ³digo:
```python

from sklearn.preprocessing import OneHotEncoder

# Instanciar o OneHotEncoder
encoder = OneHotEncoder(sparse_output=False)

# Codificar o atributo 'sexo'
sexo_encoded = encoder.fit_transform(df_clientes[['sexo']])
sexo_encoded_df = pd.DataFrame(sexo_encoded, columns=encoder.get_feature_names_out(['sexo']))

# Codificar o atributo 'genero_musical_favorito'
genero_encoded = encoder.fit_transform(df_clientes[['genero_musical_favorito']])
genero_encoded_df = pd.DataFrame(genero_encoded, columns=encoder.get_feature_names_out(['genero_musical_favorito']))

# Concatenar as colunas codificadas ao DataFrame original
df_clientes = pd.concat([df_clientes, sexo_encoded_df, genero_encoded_df], axis=1)

# Remover colunas originais categÃ³ricas
df_clientes = df_clientes.drop(columns=['sexo', 'genero_musical_favorito'])

# Exibir o DataFrame Processado
print("\nDataFrame Processado:\n")
print(df_clientes.head())

print("\nResumo do DataFrame Processado:\n")
print(df_clientes.info())

print("\nEstatÃ­sticas Descritivas do DataFrame Processado:\n")
print(df_clientes.describe())


```

#### ðŸ“„ DescriÃ§Ã£o:
- **CodificaÃ§Ã£o de Dados CategÃ³ricos**: Utilizamos `OneHotEncoder` para transformar atributos categÃ³ricos em variÃ¡veis dummy, permitindo seu uso em modelos de aprendizado de mÃ¡quina.

---

## ðŸ’¥ConclusÃ£o

Neste projeto, aplicamos uma abordagem abrangente para a anÃ¡lise e transformaÃ§Ã£o de uma base de dados de clientes, utilizando uma variedade de tÃ©cnicas estatÃ­sticas e computacionais. As etapas seguidas incluÃ­ram a limpeza e preparaÃ§Ã£o dos dados, o cÃ¡lculo de estatÃ­sticas descritivas, a anÃ¡lise de correlaÃ§Ã£o, a visualizaÃ§Ã£o grÃ¡fica dos dados, a correÃ§Ã£o de valores inconsistentes, a remoÃ§Ã£o de redundÃ¢ncias e a transformaÃ§Ã£o de dados para fins de modelagem.

Os principais resultados obtidos incluem:

- **Limpeza e PreparaÃ§Ã£o de Dados**: Conseguimos identificar e corrigir valores inconsistentes e duplicados, garantindo a qualidade dos dados para anÃ¡lises subsequentes.
- **EstatÃ­sticas Descritivas**: Foram calculadas medidas centrais (mÃ©dia, mediana, moda) e medidas de dispersÃ£o (variÃ¢ncia, desvio-padrÃ£o, amplitude), fornecendo uma visÃ£o clara das caracterÃ­sticas dos dados.
- **AnÃ¡lise de CorrelaÃ§Ã£o**: Identificamos relaÃ§Ãµes significativas entre diferentes atributos numÃ©ricos, o que pode guiar futuras anÃ¡lises e decisÃµes baseadas em dados.
- **VisualizaÃ§Ãµes GrÃ¡ficas**: Criamos diversas representaÃ§Ãµes visuais, como histogramas, box plots, grÃ¡ficos de dispersÃ£o e mapas de calor, que ajudaram a interpretar os dados de maneira intuitiva e informativa.
- **TransformaÃ§Ã£o de Dados**: Normalizamos os dados numÃ©ricos e codificamos os atributos categÃ³ricos, tornando os dados prontos para uso em modelos de aprendizado de mÃ¡quina e outras anÃ¡lises avanÃ§adas.

Este projeto demonstrou a importÃ¢ncia de um processo bem-estruturado de anÃ¡lise e transformaÃ§Ã£o de dados para extrair insights valiosos e garantir a qualidade dos dados. As tÃ©cnicas aplicadas aqui sÃ£o fundamentais para qualquer anÃ¡lise de dados robusta e servem como base para futuras anÃ¡lises mais complexas e modelagens preditivas.


